



<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#FFF">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

<link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico">
  <meta http-equiv="Cache-Control" content="no-transform">
  <meta http-equiv="Cache-Control" content="no-siteapp">


<link rel="alternate" type="application/rss+xml" title="blog_dxm" href="http://example.com/rss.xml" />
<link rel="alternate" type="application/atom+xml" title="blog_dxm" href="http://example.com/atom.xml" />
<link rel="alternate" type="application/json" title="blog_dxm" href="http://example.com/feed.json" />

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="/css/app.css?v=0.2.5">

  
  <meta name="keywords" content="Rotate,Resize" />


<link rel="canonical" href="http://example.com/2024/04/25/job/operator/rotate/">



  <title>
Rotate - 算子开发 - Job |
DDD = blog_dxm</title>
<meta name="generator" content="Hexo 6.3.0"></head>
<body itemscope itemtype="http://schema.org/WebPage">
  <div id="loading">
    <div class="cat">
      <div class="body"></div>
      <div class="head">
        <div class="face"></div>
      </div>
      <div class="foot">
        <div class="tummy-end"></div>
        <div class="bottom"></div>
        <div class="legs left"></div>
        <div class="legs right"></div>
      </div>
      <div class="paw">
        <div class="hands left"></div>
        <div class="hands right"></div>
      </div>
    </div>
  </div>
  <div id="container">
    <header id="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="inner">
        <div id="brand">
          <div class="pjax">
          
  <h1 itemprop="name headline">Rotate
  </h1>
  
<div class="meta">
  <span class="item" title="Created: 2024-04-25 21:12:10">
    <span class="icon">
      <i class="ic i-calendar"></i>
    </span>
    <span class="text">Posted on</span>
    <time itemprop="dateCreated datePublished" datetime="2024-04-25T21:12:10+08:00">2024-04-25</time>
  </span>
  <span class="item" title="Symbols count in article">
    <span class="icon">
      <i class="ic i-pen"></i>
    </span>
    <span class="text">Symbols count in article</span>
    <span>37k</span>
    <span class="text">words</span>
  </span>
  <span class="item" title="Reading time">
    <span class="icon">
      <i class="ic i-clock"></i>
    </span>
    <span class="text">Reading time</span>
    <span>34 mins.</span>
  </span>
</div>


          </div>
        </div>
        <nav id="nav">
  <div class="inner">
    <div class="toggle">
      <div class="lines" aria-label="Toggle navigation bar">
        <span class="line"></span>
        <span class="line"></span>
        <span class="line"></span>
      </div>
    </div>
    <ul class="menu">
      <li class="item title"><a href="/" rel="start">DDD</a></li>
    </ul>
    <ul class="right">
      <li class="item theme">
        <i class="ic i-sun"></i>
      </li>
      <li class="item search">
        <i class="ic i-search"></i>
      </li>
    </ul>
  </div>
</nav>

      </div>
      <div id="imgs" class="pjax">
          <img src="/2024/04/25/job/operator/rotate/rs_0001.png">
      </div>
    </header>
    <div id="waves">
      <svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto">
        <defs>
          <path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z" />
        </defs>
        <g class="parallax">
          <use xlink:href="#gentle-wave" x="48" y="0" />
          <use xlink:href="#gentle-wave" x="48" y="3" />
          <use xlink:href="#gentle-wave" x="48" y="5" />
          <use xlink:href="#gentle-wave" x="48" y="7" />
        </g>
      </svg>
    </div>
    <main>
      <div class="inner">
        <div id="main" class="pjax">
          
  <div class="article wrap">
    
<div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList">
<i class="ic i-home"></i>
<span><a href="/">Home</a></span><i class="ic i-angle-right"></i>
<span  itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/job/" itemprop="item" rel="index" title="In Job"><span itemprop="name">Job</span></a>
<meta itemprop="position" content="1" /></span>
<i class="ic i-angle-right"></i>
<span  class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/job/%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91/" itemprop="item" rel="index" title="In 算子开发"><span itemprop="name">算子开发</span></a>
<meta itemprop="position" content="2" /></span>
</div>

    <article itemscope itemtype="http://schema.org/Article" class="post block" lang="en">
  <link itemprop="mainEntityOfPage" href="http://example.com/2024/04/25/job/operator/rotate/">

  <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
    <meta itemprop="image" content="/images/dxm.jpg">
    <meta itemprop="name" content="dxm">
    <meta itemprop="description" content=", ">
  </span>

  <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
    <meta itemprop="name" content="blog_dxm">
  </span>

  <div class="body md" itemprop="articleBody">
    

    <h1 id="Resize"><a href="#Resize" class="headerlink" title="Resize"></a>Resize</h1><h2 id="Research"><a href="#Research" class="headerlink" title="Research"></a>Research</h2><blockquote>
<ul>
<li>pytorch文档: <span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy9kb2NzL3N0YWJsZS9nZW5lcmF0ZWQvdG9yY2gubm4uZnVuY3Rpb25hbC5pbnRlcnBvbGF0ZS5odG1sI3RvcmNoLm5uLmZ1bmN0aW9uYWwuaW50ZXJwb2xhdGU=">resize</span></li>
</ul>
</blockquote>
<h3 id="resize-parameter"><a href="#resize-parameter" class="headerlink" title="resize parameter"></a>resize parameter</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.functional.interpolate(<span class="built_in">input</span>, size=<span class="literal">None</span>, scale_factor=<span class="literal">None</span>, mode=<span class="string">&#x27;nearest&#x27;</span>, align_corners=<span class="literal">None</span>, recompute_scale_factor=<span class="literal">None</span>, antialias=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>resize参数<ul>
<li>input (Tensor) – the input tensor</li>
<li>size (int or Tuple[int] or Tuple[int, int] or Tuple[int, int, int]) – output spatial size</li>
<li>scale_factor (float or Tuple[float]) – multiplier for spatial size. If scale_factor is a tuple, its length has to match the number of spatial dimensions; input.dim() - 2.</li>
<li>mode (str) – algorithm used for upsampling: ‘nearest’ | ‘linear’ | ‘bilinear’ | ‘bicubic’ | ‘trilinear’ | ‘area’ | ‘nearest-exact’. Default: ‘nearest’</li>
<li>align_corners (bool, optional) – Geometrically, we consider the pixels of the input and output as squares rather than points. If set to True, the input and output tensors are aligned by the center points of their corner pixels, preserving the values at the corner pixels. If set to False, the input and output tensors are aligned by the corner points of their corner pixels, and the interpolation uses edge value padding for out-of-boundary values, making this operation independent of input size when scale_factor is kept the same. This only has an effect when mode is ‘linear’, ‘bilinear’, ‘bicubic’ or ‘trilinear’. Default: False</li>
<li>recompute_scale_factor (bool, optional) – recompute the scale_factor for use in the interpolation calculation. If recompute_scale_factor is True, then scale_factor must be passed in and scale_factor is used to compute the output size. The computed output size will be used to infer new scales for the interpolation. Note that when scale_factor is floating-point, it may differ from the recomputed scale_factor due to rounding and precision issues. If recompute_scale_factor is False, then size or scale_factor will be used directly for interpolation. Default: None.</li>
<li>antialias (bool, optional) – flag to apply anti-aliasing. Default: False. Using anti-alias option together with align_corners&#x3D;False, interpolation result would match Pillow result for downsampling operation. Supported modes: ‘bilinear’, ‘bicubic’.</li>
</ul>
</li>
</ul>
<h3 id="pytorch源码"><a href="#pytorch源码" class="headerlink" title="pytorch源码"></a>pytorch源码</h3><h4 id="bilinear-mode"><a href="#bilinear-mode" class="headerlink" title="bilinear mode"></a>bilinear mode</h4><ul>
<li>file path：&#x2F;Users&#x2F;dugen&#x2F;work&#x2F;pytorch-main&#x2F;aten&#x2F;src&#x2F;ATen&#x2F;native&#x2F;UpSample.h</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">template &lt;typename scalar_t&gt;</span><br><span class="line">static inline scalar_t area_pixel_compute_source_index(</span><br><span class="line">    scalar_t scale,</span><br><span class="line">    int64_t dst_index,</span><br><span class="line">    <span class="built_in">bool</span> align_corners,</span><br><span class="line">    <span class="built_in">bool</span> cubic) &#123;</span><br><span class="line">  <span class="keyword">if</span> (align_corners) &#123;</span><br><span class="line">    <span class="keyword">return</span> scale * dst_index;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    scalar_t src_idx = scale * (dst_index + static_cast&lt;scalar_t&gt;(<span class="number">0.5</span>)) -</span><br><span class="line">        static_cast&lt;scalar_t&gt;(<span class="number">0.5</span>);</span><br><span class="line">    // [Note] Follow Opencv resize logic:</span><br><span class="line">    // We allow negative src_idx here <span class="keyword">and</span> later will use</span><br><span class="line">    //   dx = src_idx - floorf(src_idx)</span><br><span class="line">    // to compute the <span class="string">&quot;distance&quot;</span>(which affects weights).</span><br><span class="line">    // For linear modes, weight distribution doesn<span class="string">&#x27;t matter</span></span><br><span class="line"><span class="string">    // for negative indices as they use 2 pixels to interpolate.</span></span><br><span class="line"><span class="string">    // For example, [-1, 0], they both use pixel 0 value so it</span></span><br><span class="line"><span class="string">    // doesn&#x27;</span>t affect <span class="keyword">if</span> we bound the src_idx to <span class="number">0</span> <span class="keyword">or</span> <span class="keyword">not</span>.</span><br><span class="line">    // TODO: Our current linear mode impls use unbound indices</span><br><span class="line">    // where we should <span class="keyword">and</span> then remove this cubic flag.</span><br><span class="line">    // This matters <span class="keyword">in</span> cubic mode, <span class="keyword">as</span> we might need [-<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]</span><br><span class="line">    // to interpolate <span class="keyword">and</span> the weights can be affected.</span><br><span class="line">    <span class="keyword">return</span> (!cubic &amp;&amp; src_idx &lt; static_cast&lt;scalar_t&gt;(<span class="number">0</span>)) ? scalar_t(<span class="number">0</span>)</span><br><span class="line">                                                          : src_idx;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h4 id="nearest-mode"><a href="#nearest-mode" class="headerlink" title="nearest mode"></a>nearest mode</h4><ul>
<li>file path：&#x2F;Users&#x2F;dugen&#x2F;work&#x2F;pytorch-main&#x2F;aten&#x2F;src&#x2F;ATen&#x2F;native&#x2F;UpSample.h</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">static inline int64_t nearest_neighbor_compute_source_index(</span><br><span class="line">    const <span class="built_in">float</span> scale,</span><br><span class="line">    int64_t dst_index,</span><br><span class="line">    int64_t input_size) &#123;</span><br><span class="line">  // Index computation matching OpenCV INTER_NEAREST</span><br><span class="line">  // which <span class="keyword">is</span> buggy <span class="keyword">and</span> kept <span class="keyword">for</span> BC</span><br><span class="line">  const int64_t src_index =</span><br><span class="line">      std::<span class="built_in">min</span>(static_cast&lt;int64_t&gt;(floorf(dst_index * scale)), input_size - <span class="number">1</span>);</span><br><span class="line">  <span class="keyword">return</span> src_index;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Implement"><a href="#Implement" class="headerlink" title="Implement"></a>Implement</h2><h3 id="resize行为"><a href="#resize行为" class="headerlink" title="resize行为"></a>resize行为</h3><h4 id="公式推导"><a href="#公式推导" class="headerlink" title="公式推导"></a>公式推导</h4><ul>
<li>Nearest mode<ul>
<li>src_h &#x3D; dst_h * (src_H &#x2F; dst_H)</li>
<li>src_w &#x3D; dst_w * (src_W &#x2F; dst_W)</li>
<li>p_(dst_h, dst_w) &#x3D; p_(src_h, src_w)</li>
</ul>
</li>
<li>Bilinear mode<ul>
<li>align_corners &#x3D; true<ul>
<li>output2input addr<ul>
<li>src_h &#x3D; (src_H-1) &#x2F; (dst_H-1) * dst_h</li>
<li>src_w &#x3D; (src_W-1) &#x2F; (dst_W-1) * dst_w</li>
</ul>
</li>
<li>fx&#x2F;fy &#x3D;&#x3D;&#x3D;&gt; sample_addr + weight<ul>
<li>ceil(src_h) !&#x3D; src_h ？w_ud &#x3D; ceil(src_h) - src_h : 1; i_ud &#x3D; floor(src_h)</li>
<li>ceil(src_w) !&#x3D; src_w ？w_lr &#x3D; ceil(src_w) - src_w : 1; i_lr &#x3D; floor(src_w)</li>
</ul>
</li>
<li>计算output(dst_h, dst_w)值<ul>
<li>i_00 &#x3D; p_(i_ud, i_lr)、i_01 &#x3D; p_(i_ud, i_lr + 1)、i_10 &#x3D; p_(i_ud + 1, i_lr)、i_11 &#x3D; p_(i_ud + 1, i_lr + 1)</li>
<li>w_00 &#x3D; w_ud * w_lr、w_01 &#x3D; w_ud * (1 - w_lr)、w_10 &#x3D; (1 - w_ud) * w_lr、w_11 &#x3D; (1 - w_ud) * (1 - w_lr)</li>
<li>p(dst_h, dst_w)&#x3D;i_00 * w_00 + i_01 * w_01 + i_10 * w_10 + i_11 * w_11</li>
</ul>
</li>
</ul>
</li>
<li>align_corners &#x3D; false<ul>
<li>output2input addr<ul>
<li>src_h &#x3D; (dst_h + 0.5) * factor_h - 0.5, factor_h &#x3D; src_H &#x2F; dst_H</li>
<li>src_w &#x3D; (dst_w + 0.5) * factor_w - 0.5, factor_w &#x3D; src_W &#x2F; dst_W</li>
</ul>
</li>
<li>fx&#x2F;fy &#x3D;&#x3D;&#x3D;&gt; sample_addr + weight<ul>
<li>ceil(src_h) !&#x3D; src_h ？w_ud &#x3D; ceil(src_h) - src_h : 1; i_ud &#x3D; floor(src_h)</li>
<li>ceil(src_w) !&#x3D; src_w ？w_lr &#x3D; ceil(src_w) - src_w : 1; i_lr &#x3D; floor(src_w)</li>
</ul>
</li>
<li>计算output(dst_h, dst_w)值<ul>
<li>i_00 &#x3D; p_(i_ud, i_lr)、i_01 &#x3D; p_(i_ud, i_lr + 1)、i_10 &#x3D; p_(i_ud + 1, i_lr)、i_11 &#x3D; p_(i_ud + 1, i_lr + 1)</li>
<li>w_00 &#x3D; w_ud * w_lr、w_01 &#x3D; w_ud * (1 - w_lr)、w_10 &#x3D; (1 - w_ud) * w_lr、w_11 &#x3D; (1 - w_ud) * (1 - w_lr)</li>
<li>p(dst_h, dst_w)&#x3D;i_00 * w_00 + i_01 * w_01 + i_10 * w_10 + i_11 * w_11</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h4 id="resize图示"><a href="#resize图示" class="headerlink" title="resize图示"></a>resize图示</h4><ul>
<li><p>Nearest mode<br><img data-src="/2024/04/25/job/operator/rotate/rs_0002.jpg" alt="rs_0002" title="resize nearest mode"></p>
</li>
<li><p>Bilinear mode<br><img data-src="/2024/04/25/job/operator/rotate/rs_0003.jpg" alt="rs_0003" title="resize bilinear mode"></p>
</li>
<li><p>workflow<br><img data-src="/2024/04/25/job/operator/rotate/rs_0004.jpg" alt="rs_0004" title="resize workflow"></p>
</li>
</ul>
<h3 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h3><h4 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h4><h5 id="align-corner-true-bilinear"><a href="#align-corner-true-bilinear" class="headerlink" title="align_corner &#x3D; true (bilinear)"></a>align_corner &#x3D; true (bilinear)</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更改打印选项</span></span><br><span class="line">torch.set_printoptions(linewidth=<span class="number">120</span>)</span><br><span class="line">debug = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">N, IC, IH, IW = <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span></span><br><span class="line">scale_factor = <span class="number">4</span></span><br><span class="line">output_size = (IH * scale_factor, IW * scale_factor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建输入张量</span></span><br><span class="line"><span class="built_in">input</span> = torch.arange(<span class="number">1</span>, N * IC * IH * IW + <span class="number">1</span>, dtype=torch.float32).reshape(N, IC, IH, IW)</span><br><span class="line"></span><br><span class="line">output_pytorch = F.interpolate(<span class="built_in">input</span>, output_size, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners= <span class="literal">True</span>)</span><br><span class="line"><span class="comment"># 这里的(4,4)指的是将后两个维度放缩成4*4的大小</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原数组尺寸:&#x27;</span>, <span class="built_in">input</span>.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;bilinear采样尺寸:&#x27;</span>, output_pytorch.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=========================== interpolate pytorch, align_corners = True ===========================\n&quot;</span>, output_pytorch)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">interpolate_tensor</span>(<span class="params"><span class="built_in">input</span>, output_size</span>):</span><br><span class="line">    <span class="comment"># 获取输入和输出的大小</span></span><br><span class="line">    input_size = <span class="built_in">input</span>.size()</span><br><span class="line">    batch_size, channels, input_height, input_width = input_size</span><br><span class="line">    output_height, output_width = output_size</span><br><span class="line">    output = torch.zeros(batch_size, channels, output_height, output_width)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算每个点的值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(output_height):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(output_width):</span><br><span class="line">            src_h = ((input_height - <span class="number">1</span>) * i) / (output_height - <span class="number">1</span>)      <span class="comment"># H方向 : </span></span><br><span class="line">            src_w = ((input_width - <span class="number">1</span>) * j) / (output_width - <span class="number">1</span>)        <span class="comment"># W方向 : </span></span><br><span class="line"></span><br><span class="line">            h_weights = torch.tensor([math.ceil(src_h) - src_h <span class="keyword">if</span> math.ceil(src_h) != src_h <span class="keyword">else</span> <span class="number">1</span>, src_h - math.floor(src_h)])     <span class="comment"># 1 - v | v</span></span><br><span class="line">            w_weights = torch.tensor([math.ceil(src_w) - src_w <span class="keyword">if</span> math.ceil(src_w) != src_w <span class="keyword">else</span> <span class="number">1</span>, src_w - math.floor(src_w)])     <span class="comment"># 1 - u | u</span></span><br><span class="line"></span><br><span class="line">            h_indices = torch.tensor([math.floor(src_h), <span class="built_in">min</span>(math.ceil(src_h), input_height - <span class="number">1</span>)])        <span class="comment"># i | min(i+1, input_height - 1)</span></span><br><span class="line">            w_indices = torch.tensor([math.floor(src_w), <span class="built_in">min</span>(math.ceil(src_w), input_width - <span class="number">1</span>)])         <span class="comment"># j | min(j+1, input_width - 1)</span></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> debug:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;(idx_out_h, idx_out_w) = (<span class="subst">&#123;j&#125;</span>, <span class="subst">&#123;i&#125;</span>), (src_h, src_w) = (<span class="subst">&#123;src_h&#125;</span>, <span class="subst">&#123;src_w&#125;</span>)&quot;</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;before boundary processing: h_weight0 = <span class="subst">&#123;h_weights[<span class="number">0</span>]&#125;</span>, h_weight1 = <span class="subst">&#123;h_weights[<span class="number">1</span>]&#125;</span>, w_weight0 = <span class="subst">&#123;w_weights[<span class="number">0</span>]&#125;</span>, w_weight1 = <span class="subst">&#123;w_weights[<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;before boundary processing: h_indices0 = <span class="subst">&#123;h_indices[<span class="number">0</span>]&#125;</span>, h_indices1 = <span class="subst">&#123;h_indices[<span class="number">1</span>]&#125;</span>, w_indices0 = <span class="subst">&#123;w_indices[<span class="number">0</span>]&#125;</span>, w_indices1 = <span class="subst">&#123;w_indices[<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;before boundary processing: w00 = <span class="subst">&#123;h_weights[<span class="number">0</span>] * w_weights[<span class="number">0</span>]&#125;</span>, w01 = <span class="subst">&#123;h_weights[<span class="number">0</span>] * w_weights[<span class="number">1</span>]&#125;</span>, w10 = <span class="subst">&#123;h_weights[<span class="number">1</span>] * w_weights[<span class="number">0</span>]&#125;</span>, w11 = <span class="subst">&#123;h_weights[<span class="number">1</span>] * w_weights[<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;before boundary processing: i00 = (<span class="subst">&#123;h_indices[<span class="number">0</span>]&#125;</span>, <span class="subst">&#123;w_indices[<span class="number">0</span>]&#125;</span>), i01 = (<span class="subst">&#123;h_indices[<span class="number">0</span>]&#125;</span>, <span class="subst">&#123;w_indices[<span class="number">1</span>]&#125;</span>), i10 = (<span class="subst">&#123;h_indices[<span class="number">1</span>]&#125;</span>, <span class="subst">&#123;w_indices[<span class="number">0</span>]&#125;</span>), i11 = (<span class="subst">&#123;h_indices[<span class="number">1</span>]&#125;</span>, <span class="subst">&#123;w_indices[<span class="number">1</span>]&#125;</span>)&quot;</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;before boundary processing: i00 = <span class="subst">&#123;<span class="built_in">input</span>[:, :, h_indices[<span class="number">0</span>], w_indices[<span class="number">0</span>]].item()&#125;</span>, i01 = <span class="subst">&#123;<span class="built_in">input</span>[:, :, h_indices[<span class="number">0</span>], w_indices[<span class="number">1</span>]].item()&#125;</span>, i10 = <span class="subst">&#123;<span class="built_in">input</span>[:, :, h_indices[<span class="number">1</span>], w_indices[<span class="number">0</span>]].item()&#125;</span>, i11 = <span class="subst">&#123;<span class="built_in">input</span>[:, :, h_indices[<span class="number">1</span>], w_indices[<span class="number">1</span>]].item()&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">            output[:, :, i, j] = (</span><br><span class="line">                h_weights[<span class="number">0</span>] * w_weights[<span class="number">0</span>] * <span class="built_in">input</span>[:, :, h_indices[<span class="number">0</span>], w_indices[<span class="number">0</span>]] +</span><br><span class="line">                h_weights[<span class="number">0</span>] * w_weights[<span class="number">1</span>] * <span class="built_in">input</span>[:, :, h_indices[<span class="number">0</span>], w_indices[<span class="number">1</span>]] +</span><br><span class="line">                h_weights[<span class="number">1</span>] * w_weights[<span class="number">0</span>] * <span class="built_in">input</span>[:, :, h_indices[<span class="number">1</span>], w_indices[<span class="number">0</span>]] +</span><br><span class="line">                h_weights[<span class="number">1</span>] * w_weights[<span class="number">1</span>] * <span class="built_in">input</span>[:, :, h_indices[<span class="number">1</span>], w_indices[<span class="number">1</span>]]</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">output_manual = interpolate_tensor(<span class="built_in">input</span>, output_size)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n=========================== interpolate manual ===========================&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(output_manual)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n=========================== compare interpolate ===========================&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> torch.allclose(output_pytorch, output_manual, atol=<span class="number">1e-4</span>):</span><br><span class="line">    diff = (torch.<span class="built_in">abs</span>(output_pytorch - output_manual) &gt; <span class="number">1e-4</span>).nonzero(as_tuple=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(diff[<span class="number">0</span>].shape[<span class="number">0</span>]):</span><br><span class="line">        index = <span class="built_in">tuple</span>(d[i].item() <span class="keyword">for</span> d <span class="keyword">in</span> diff)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;output_pytorch<span class="subst">&#123;index&#125;</span> = <span class="subst">&#123;output_pytorch[index]&#125;</span>, output_manual<span class="subst">&#123;index&#125;</span> = <span class="subst">&#123;output_manual[index]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;两个张量相等&quot;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="align-corner-false-bilinear"><a href="#align-corner-false-bilinear" class="headerlink" title="align_corner &#x3D; false (bilinear)"></a>align_corner &#x3D; false (bilinear)</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更改打印选项</span></span><br><span class="line">torch.set_printoptions(linewidth=<span class="number">120</span>)</span><br><span class="line">debug = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">N, IC, IH, IW = <span class="number">1</span>, <span class="number">8</span>, <span class="number">200</span>, <span class="number">100</span></span><br><span class="line">scale_factor = <span class="number">2</span></span><br><span class="line">output_size = (IH * scale_factor, IW * scale_factor)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建输入张量</span></span><br><span class="line"><span class="built_in">input</span> = torch.arange(<span class="number">1</span>, N * IC * IH * IW + <span class="number">1</span>, dtype=torch.float32).reshape(N, IC, IH, IW)</span><br><span class="line"></span><br><span class="line">output_pytorch = F.interpolate(<span class="built_in">input</span>, output_size, mode=<span class="string">&#x27;bilinear&#x27;</span>, align_corners= <span class="literal">False</span>)</span><br><span class="line"><span class="comment"># 这里的(4,4)指的是将后两个维度放缩成4*4的大小</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;原数组尺寸:&#x27;</span>, <span class="built_in">input</span>.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;bilinear采样尺寸:&#x27;</span>, output_pytorch.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=========================== interpolate pytorch, align_corners = True ===========================\n&quot;</span>, output_pytorch)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">interpolate_tensor</span>(<span class="params"><span class="built_in">input</span>, output_size</span>):</span><br><span class="line">    <span class="comment"># 获取输入和输出的大小</span></span><br><span class="line">    input_size = <span class="built_in">input</span>.size()</span><br><span class="line">    batch_size, channels, input_height, input_width = input_size</span><br><span class="line">    output_height, output_width = output_size</span><br><span class="line">    output = torch.zeros(batch_size, channels, output_height, output_width)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算每个点的值</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(output_height):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(output_width):</span><br><span class="line">            src_h = (i + <span class="number">0.5</span>) * (input_height / output_height) - <span class="number">0.5</span></span><br><span class="line">            src_w = (j + <span class="number">0.5</span>) * (input_width / output_width) - <span class="number">0.5</span></span><br><span class="line"></span><br><span class="line">            h_indices = torch.tensor([<span class="built_in">int</span>(src_h), <span class="built_in">min</span>(<span class="built_in">int</span>(src_h) + <span class="number">1</span>, input_height - <span class="number">1</span>)])</span><br><span class="line">            w_indices = torch.tensor([<span class="built_in">int</span>(src_w), <span class="built_in">min</span>(<span class="built_in">int</span>(src_w) + <span class="number">1</span>, input_width - <span class="number">1</span>)])</span><br><span class="line"></span><br><span class="line">            src_h = <span class="built_in">min</span>(<span class="built_in">max</span>(<span class="number">0</span>, src_h), IH - <span class="number">1</span>)</span><br><span class="line">            src_w = <span class="built_in">min</span>(<span class="built_in">max</span>(<span class="number">0</span>, src_w), IW - <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">            h_weights = torch.tensor([<span class="number">1</span> - (src_h % <span class="number">1</span>), src_h % <span class="number">1</span>])</span><br><span class="line">            w_weights = torch.tensor([<span class="number">1</span> - (src_w % <span class="number">1</span>), src_w % <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">            scale_factor_h = (output_height / input_height) <span class="keyword">if</span> (output_height &gt;= input_height) <span class="keyword">else</span> (input_height / output_height)</span><br><span class="line">            scale_factor_w = output_width / input_width <span class="keyword">if</span> (output_width &gt;= input_width) <span class="keyword">else</span> (input_width / output_width)</span><br><span class="line">            <span class="keyword">if</span> debug:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;(idx_out_h, idx_out_w) = (<span class="subst">&#123;i&#125;</span>, <span class="subst">&#123;j&#125;</span>), (src_h, src_w) = (<span class="subst">&#123;src_h&#125;</span>, <span class="subst">&#123;src_w&#125;</span>)&quot;</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;before boundary processing: h_weight0 = <span class="subst">&#123;h_weights[<span class="number">0</span>]&#125;</span>, h_weight1 = <span class="subst">&#123;h_weights[<span class="number">1</span>]&#125;</span>, w_weight0 = <span class="subst">&#123;w_weights[<span class="number">0</span>]&#125;</span>, w_weight1 = <span class="subst">&#123;w_weights[<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;before boundary processing: h_indices0 = <span class="subst">&#123;h_indices[<span class="number">0</span>]&#125;</span>, h_indices1 = <span class="subst">&#123;h_indices[<span class="number">1</span>]&#125;</span>, w_indices0 = <span class="subst">&#123;w_indices[<span class="number">0</span>]&#125;</span>, w_indices1 = <span class="subst">&#123;w_indices[<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> debug:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;before boundary processing: w00 = <span class="subst">&#123;h_weights[<span class="number">0</span>] * w_weights[<span class="number">0</span>]&#125;</span>, w01 = <span class="subst">&#123;h_weights[<span class="number">0</span>] * w_weights[<span class="number">1</span>]&#125;</span>, w10 = <span class="subst">&#123;h_weights[<span class="number">1</span>] * w_weights[<span class="number">0</span>]&#125;</span>, w11 = <span class="subst">&#123;h_weights[<span class="number">1</span>] * w_weights[<span class="number">1</span>]&#125;</span>&quot;</span>)</span><br><span class="line">            output[:, :, i, j] = (</span><br><span class="line">                h_weights[<span class="number">0</span>] * w_weights[<span class="number">0</span>] * <span class="built_in">input</span>[:, :, h_indices[<span class="number">0</span>], w_indices[<span class="number">0</span>]] +</span><br><span class="line">                h_weights[<span class="number">0</span>] * w_weights[<span class="number">1</span>] * <span class="built_in">input</span>[:, :, h_indices[<span class="number">0</span>], w_indices[<span class="number">1</span>]] +</span><br><span class="line">                h_weights[<span class="number">1</span>] * w_weights[<span class="number">0</span>] * <span class="built_in">input</span>[:, :, h_indices[<span class="number">1</span>], w_indices[<span class="number">0</span>]] +</span><br><span class="line">                h_weights[<span class="number">1</span>] * w_weights[<span class="number">1</span>] * <span class="built_in">input</span>[:, :, h_indices[<span class="number">1</span>], w_indices[<span class="number">1</span>]]</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> debug:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;before boundary processing: i00 = (<span class="subst">&#123;h_indices[<span class="number">0</span>]&#125;</span>, <span class="subst">&#123;w_indices[<span class="number">0</span>]&#125;</span>), i01 = (<span class="subst">&#123;h_indices[<span class="number">0</span>]&#125;</span>, <span class="subst">&#123;w_indices[<span class="number">1</span>]&#125;</span>), i10 = (<span class="subst">&#123;h_indices[<span class="number">1</span>]&#125;</span>, <span class="subst">&#123;w_indices[<span class="number">0</span>]&#125;</span>), i11 = (<span class="subst">&#123;h_indices[<span class="number">1</span>]&#125;</span>, <span class="subst">&#123;w_indices[<span class="number">1</span>]&#125;</span>)&quot;</span>)</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;before boundary processing: i00 = <span class="subst">&#123;<span class="built_in">input</span>[:, :, h_indices[<span class="number">0</span>], w_indices[<span class="number">0</span>]].item()&#125;</span>, i01 = <span class="subst">&#123;<span class="built_in">input</span>[:, :, h_indices[<span class="number">0</span>], w_indices[<span class="number">1</span>]].item()&#125;</span>, i10 = <span class="subst">&#123;<span class="built_in">input</span>[:, :, h_indices[<span class="number">1</span>], w_indices[<span class="number">0</span>]].item()&#125;</span>, i11 = <span class="subst">&#123;<span class="built_in">input</span>[:, :, h_indices[<span class="number">1</span>], w_indices[<span class="number">1</span>]].item()&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">output_manual = interpolate_tensor(<span class="built_in">input</span>, output_size)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n=========================== interpolate manual ===========================&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(output_manual)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n=========================== compare interpolate ===========================&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> torch.allclose(output_pytorch, output_manual, atol=<span class="number">1e-4</span>):</span><br><span class="line">    diff = (torch.<span class="built_in">abs</span>(output_pytorch - output_manual) &gt; <span class="number">1e-4</span>).nonzero(as_tuple=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(diff[<span class="number">0</span>].shape[<span class="number">0</span>]):</span><br><span class="line">        index = <span class="built_in">tuple</span>(d[i].item() <span class="keyword">for</span> d <span class="keyword">in</span> diff)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;output_pytorch<span class="subst">&#123;index&#125;</span> = <span class="subst">&#123;output_pytorch[index]&#125;</span>, output_manual<span class="subst">&#123;index&#125;</span> = <span class="subst">&#123;output_manual[index]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;两个张量相等&quot;</span>)</span><br></pre></td></tr></table></figure>

<h5 id="nearest-mode-1"><a href="#nearest-mode-1" class="headerlink" title="nearest mode"></a>nearest mode</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="comment"># 更改打印选项</span></span><br><span class="line">torch.set_printoptions(linewidth=<span class="number">120</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#################################################################################################################</span></span><br><span class="line">N, IH, IW, IC = <span class="number">1</span>, <span class="number">200</span>, <span class="number">100</span>, <span class="number">8</span></span><br><span class="line">output_size = (<span class="number">2</span> * IH, <span class="number">2</span> * IW)</span><br><span class="line">input_bin = np.fromfile(<span class="string">&quot;/home/dugen/project_dxm/pytorch-main/project_dxm/resize/input.bin&quot;</span>, dtype=np.int8)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=========================== resize input shape ===========================&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(input_bin.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reshape the input data to NHWC format</span></span><br><span class="line">resize_input_reshape = input_bin.reshape(N, IH, IW, IC)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=========================== resize input reshape ===========================&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(resize_input_reshape.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert the numpy array to a torch tensor</span></span><br><span class="line">resize_input_tensor = torch.from_numpy(resize_input_reshape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change the data format from NHWC to NCHW</span></span><br><span class="line"><span class="built_in">input</span> = resize_input_tensor.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert the input tensor to float type</span></span><br><span class="line"><span class="built_in">input</span> = <span class="built_in">input</span>.<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=========================== input first 4 channels ===========================&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">input</span>[<span class="number">0</span>, :<span class="number">4</span>])</span><br><span class="line"><span class="comment">##################################################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># # ##################################################################################################################</span></span><br><span class="line"><span class="comment"># input = torch.arange(1, 17, dtype=torch.int8).reshape(1, 1, 4, 4)</span></span><br><span class="line"><span class="comment"># output_size = (6, 10)</span></span><br><span class="line"><span class="comment"># input = input.float()</span></span><br><span class="line"><span class="comment"># # ##################################################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##################################################################################################################</span></span><br><span class="line">output_pytorch = F.interpolate(<span class="built_in">input</span>, output_size, mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;nearest采样尺寸:&#x27;</span>, output_pytorch.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=========================== interpolate pytorch nearest mode ===========================\n&quot;</span>, output_pytorch)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define the range for truncation</span></span><br><span class="line">min_value = -<span class="number">128</span></span><br><span class="line">max_value = <span class="number">127</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Round the data</span></span><br><span class="line">rounded_data = torch.<span class="built_in">round</span>(output_pytorch)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Truncate the data to the specified range</span></span><br><span class="line">clamped_data = torch.clamp(rounded_data, min_value, max_value)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert the data to int8_t type</span></span><br><span class="line">output_pytorch = clamped_data.to(torch.int8)</span><br><span class="line"><span class="comment">##################################################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># def custom_interpolate(input, output_size):</span></span><br><span class="line"><span class="comment">#     input_size = input.size()</span></span><br><span class="line"><span class="comment">#     batch_size, channels, input_height, input_width = input_size</span></span><br><span class="line"><span class="comment">#     output_height, output_width = output_size</span></span><br><span class="line"><span class="comment">#     output = torch.zeros(batch_size, channels, output_height, output_width)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#     for dst_y in range(output_height):</span></span><br><span class="line"><span class="comment">#         for dst_x in range(output_width):</span></span><br><span class="line"><span class="comment">#             src_y = int(dst_y * (input_height / output_height))</span></span><br><span class="line"><span class="comment">#             src_x = int(dst_x * (input_width / output_width))</span></span><br><span class="line"><span class="comment">#             print(&quot;(&quot;, &quot;&#123;:.2f&#125;&quot;.format(dst_y * (input_height / output_height)), &quot;&#123;:.2f&#125;&quot;.format(dst_x * (input_width / output_width)), &quot;)&quot;, end = &quot;&quot;) </span></span><br><span class="line"><span class="comment">#             output[:, :, dst_y, dst_x] = input[:, :, src_y, src_x]</span></span><br><span class="line"><span class="comment">#         print(&quot;&quot;)</span></span><br><span class="line"><span class="comment">#     return output</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># output_manual = custom_interpolate(input, output_size)</span></span><br><span class="line"><span class="comment"># print(&quot;\n=========================== interpolate manual ===========================&quot;)</span></span><br><span class="line"><span class="comment"># print(output_manual)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">##################################################################################################################</span></span><br><span class="line">OH, OW, OC = IH * <span class="number">2</span>, IW * <span class="number">2</span>, IC</span><br><span class="line">output_bin = np.fromfile(<span class="string">&quot;/home/dugen/project_dxm/pytorch-main/project_dxm/resize/output.bin&quot;</span>, dtype=np.int8)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=========================== resize output shape ===========================&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(output_bin.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reshape the output data to NHWC format</span></span><br><span class="line">resize_output_reshape = output_bin.reshape(N, OH, OW, IC)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=========================== resize output reshape ===========================&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(resize_output_reshape.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert the numpy array to a torch tensor</span></span><br><span class="line">resize_output_tensor = torch.from_numpy(resize_output_reshape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Change the data format from NHWC to NCHW</span></span><br><span class="line">output_manual = resize_output_tensor.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;=========================== interpolate manual nearest mode ===========================\n&quot;</span>, output_manual)</span><br><span class="line"><span class="comment">##################################################################################################################</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n=========================== compare interpolate ===========================&quot;</span>)</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> torch.allclose(output_pytorch, output_manual, atol=<span class="number">1e-4</span>):</span><br><span class="line">    diff = (torch.<span class="built_in">abs</span>(output_pytorch - output_manual) &gt; <span class="number">1e-4</span>).nonzero(as_tuple=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(diff[<span class="number">0</span>].shape[<span class="number">0</span>]):</span><br><span class="line">        index = <span class="built_in">tuple</span>(d[i].item() <span class="keyword">for</span> d <span class="keyword">in</span> diff)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;output_pytorch<span class="subst">&#123;index&#125;</span> = <span class="subst">&#123;output_pytorch[index]&#125;</span>, output_manual<span class="subst">&#123;index&#125;</span> = <span class="subst">&#123;output_manual[index]&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;两个张量相等&quot;</span>)</span><br></pre></td></tr></table></figure>

<h4 id="C"><a href="#C" class="headerlink" title="C++"></a>C++</h4><h5 id="resize-hpp"><a href="#resize-hpp" class="headerlink" title="resize.hpp"></a>resize.hpp</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">pragma</span> once</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;util.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cpuOpUtils.hpp&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tool_macro.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;tool_function.h&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;random&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;cstdlib&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;unistd.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sys/stat.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> BILINEAR_MODE</span></span><br><span class="line"><span class="comment">// #define ALIGN_CORNER_TRUE_MODE</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> TILE_PER_CLUSTER 4</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="type">resize_golden_t</span> = std::vector&lt;<span class="type">int8_t</span>&gt;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResizeCpuOp</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="built_in">ResizeCpuOp</span>(<span class="type">const</span> <span class="type">uint32_t</span>&amp; total_tile_num_, <span class="type">const</span> <span class="type">uint32_t</span>&amp; slice_num_, <span class="type">const</span> <span class="type">uint32_t</span>&amp; ih_, <span class="type">const</span> <span class="type">uint32_t</span>&amp; iw_, </span><br><span class="line">                <span class="type">const</span> <span class="type">uint32_t</span>&amp; ic_, <span class="type">const</span> <span class="type">uint32_t</span>&amp; scale_factor);</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="type">resize_golden_t</span> <span class="title">GenGoldenInput</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="type">resize_golden_t</span> <span class="title">GenGoldenOutput</span><span class="params">(<span class="type">const</span> <span class="type">resize_golden_t</span>&amp; input)</span></span>;</span><br><span class="line">    <span class="function"><span class="type">const</span> <span class="type">resize_golden_t</span>&amp; <span class="title">GetGoldenInputInorder</span><span class="params">()</span> <span class="type">const</span></span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">GenGoldenData</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">    std::vector&lt;<span class="type">int</span>&gt; shape_;</span><br><span class="line">    <span class="type">uint32_t</span> total_tile_num_;</span><br><span class="line">    <span class="type">uint32_t</span> slice_num_;</span><br><span class="line">    <span class="type">uint32_t</span> scale_factor_;</span><br><span class="line">    <span class="type">uint32_t</span> ih_;</span><br><span class="line">    <span class="type">uint32_t</span> iw_;</span><br><span class="line">    <span class="type">uint32_t</span> ic_;</span><br><span class="line">    <span class="type">uint32_t</span> oh_;</span><br><span class="line">    <span class="type">uint32_t</span> ow_;</span><br><span class="line">    <span class="type">uint32_t</span> oc_;</span><br><span class="line">    <span class="type">uint32_t</span> total_ic_;</span><br><span class="line"></span><br><span class="line">    <span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">float</span> min_value = <span class="number">-128</span>;</span><br><span class="line">    <span class="type">static</span> <span class="keyword">constexpr</span> <span class="type">float</span> max_value = <span class="number">127</span>;</span><br><span class="line">    <span class="function"><span class="type">void</span> <span class="title">float_to_int8</span><span class="params">(std::vector&lt;<span class="type">float</span>&gt;&amp; input_data, std::vector&lt;<span class="type">int8_t</span>&gt;&amp; output_data)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="type">resize_golden_t</span> golden_input_int8;  <span class="comment">// [NHWC]</span></span><br><span class="line">    <span class="type">resize_golden_t</span> golden_input_inorder_int8;</span><br><span class="line">    <span class="type">resize_golden_t</span> golden_output_int8;</span><br><span class="line">    <span class="type">resize_golden_t</span> golden_output_inorder_int8;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h5 id="resize-cpp"><a href="#resize-cpp" class="headerlink" title="resize.cpp"></a>resize.cpp</h5><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;resize_cpuop.hpp&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> BILINEAR_MODE</span></span><br><span class="line">    <span class="type">bool</span> if_bilinear_mode = <span class="literal">true</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    <span class="type">bool</span> if_bilinear_mode = <span class="literal">false</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> ALIGN_CORNER_TRUE_MODE</span></span><br><span class="line">    <span class="type">bool</span> if_align_corner_true = <span class="literal">true</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">    <span class="type">bool</span> if_align_corner_true = <span class="literal">false</span>;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">float</span> ResizeCpuOp::min_value;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="type">float</span> ResizeCpuOp::max_value;</span><br><span class="line"></span><br><span class="line">ResizeCpuOp::<span class="built_in">ResizeCpuOp</span>(<span class="type">const</span> <span class="type">uint32_t</span>&amp; total_tile_num, <span class="type">const</span> <span class="type">uint32_t</span>&amp; slice_num_, <span class="type">const</span> <span class="type">uint32_t</span>&amp; ih_, <span class="type">const</span> <span class="type">uint32_t</span>&amp; iw_, <span class="type">const</span> <span class="type">uint32_t</span>&amp; ic_, </span><br><span class="line">                         <span class="type">const</span> <span class="type">uint32_t</span>&amp; scale_factor) : <span class="built_in">total_tile_num_</span>(total_tile_num), </span><br><span class="line">                         <span class="built_in">slice_num_</span>(slice_num_), <span class="built_in">ih_</span>(ih_), <span class="built_in">iw_</span>(iw_), <span class="built_in">ic_</span>(ic_), <span class="built_in">scale_factor_</span>(scale_factor)&#123;</span><br><span class="line">    oh_ = ih_ * scale_factor_;</span><br><span class="line">    ow_ = iw_ * scale_factor_;</span><br><span class="line">    oc_ = ic_;</span><br><span class="line">    total_ic_ = ic_ * total_tile_num_;</span><br><span class="line"></span><br><span class="line">    golden_input_int8.<span class="built_in">resize</span>(total_tile_num_ * ih_ * iw_ * ic_);</span><br><span class="line">    golden_output_int8.<span class="built_in">resize</span>(total_tile_num_ * oh_ * ow_ * oc_);</span><br><span class="line">    golden_input_inorder_int8.<span class="built_in">resize</span>(total_tile_num_ * ih_ * iw_ * ic_);</span><br><span class="line">    golden_output_inorder_int8.<span class="built_in">resize</span>(total_tile_num_ * oh_ * ow_ * oc_);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">resize_golden_t</span> <span class="title">ResizeCpuOp::GenGoldenInput</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="type">unsigned</span> seed = <span class="number">123</span>;</span><br><span class="line">    <span class="function">std::mt19937 <span class="title">gen</span><span class="params">(seed)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 用于生成不一致随机数的设备种子</span></span><br><span class="line">    <span class="comment">// std::random_device rd;</span></span><br><span class="line">    <span class="comment">// std::mt19937 gen(rd());</span></span><br><span class="line">    <span class="function">std::uniform_int_distribution&lt;<span class="type">int</span>&gt; <span class="title">dis</span><span class="params">(<span class="number">-128</span>, <span class="number">127</span>)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> idx_tile = <span class="number">0</span>; idx_tile &lt; total_tile_num_; idx_tile++) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> idx_h = <span class="number">0</span>; idx_h &lt; ih_; ++idx_h) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> idx_w = <span class="number">0</span>; idx_w &lt; iw_; ++idx_w) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> idx_c = <span class="number">0</span>; idx_c &lt; ic_; ++idx_c) &#123;</span><br><span class="line">                    <span class="type">int8_t</span> val = <span class="built_in">dis</span>(gen);</span><br><span class="line">                    <span class="comment">// int8_t val = 1;</span></span><br><span class="line">                    <span class="type">int</span> idx_elem = idx_h * iw_ * total_ic_ + idx_w * total_ic_ + idx_tile * ic_ + idx_c;</span><br><span class="line">                    golden_input_int8.<span class="built_in">at</span>(idx_elem) = val;</span><br><span class="line">                    <span class="type">int</span> idx_elem_inorder = idx_tile * ih_ * iw_ * ic_ + idx_h * iw_ * ic_ + idx_w * ic_ + idx_c;</span><br><span class="line">                    golden_input_inorder_int8.<span class="built_in">at</span>(idx_elem_inorder) = val;</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// int idx_elem = idx_h * iw_ * total_ic_ + idx_w * total_ic_ + idx_tile * ic_ + idx_c;</span></span><br><span class="line">                    <span class="comment">// golden_input_int8.at(idx_elem) = idx_tile * ih_ * iw_ * ic_ + idx_c * ih_ * iw_ + idx_h * iw_ + idx_w + 1;</span></span><br><span class="line">                    <span class="comment">// int idx_elem_inorder = idx_tile * ih_ * iw_ * ic_ + idx_h * iw_ * ic_ + idx_w * ic_ + idx_c;</span></span><br><span class="line">                    <span class="comment">// golden_input_inorder_int8.at(idx_elem_inorder) = idx_tile * ih_ * iw_ * ic_ + idx_c * ih_ * iw_ + idx_h * iw_ + idx_w + 1;</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> golden_input_int8;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">const</span> <span class="type">resize_golden_t</span>&amp; <span class="title">ResizeCpuOp::GetGoldenInputInorder</span><span class="params">()</span> <span class="type">const</span> </span>&#123; </span><br><span class="line">    <span class="keyword">return</span> golden_input_inorder_int8; </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">mkdir_check</span><span class="params">(<span class="type">const</span> std::string&amp; dir)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">access</span>(dir.<span class="built_in">c_str</span>(), <span class="number">0</span>) == <span class="number">0</span>) &#123;</span><br><span class="line">        std::string cmd = <span class="string">&quot;rm -rf &quot;</span> + dir;</span><br><span class="line">        <span class="built_in">system</span>(cmd.<span class="built_in">c_str</span>());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">mkdir</span>(dir.<span class="built_in">c_str</span>(), S_IRWXU);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ResizeCpuOp::GenGoldenData</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    std::string path_prefix = <span class="string">&quot;./resize_bin/&quot;</span>;</span><br><span class="line">    <span class="built_in">mkdir_check</span>(path_prefix);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// input</span></span><br><span class="line">    std::string name = path_prefix + <span class="string">&quot;resize_input_bilinear.bin&quot;</span>;</span><br><span class="line">    std::ofstream ofs;</span><br><span class="line">    ofs.<span class="built_in">open</span>(name, std::ios::binary | std::ios::out);</span><br><span class="line">    <span class="built_in">assert</span>((ih_ * iw_ * ic_ * total_tile_num_) == golden_input_inorder_int8.<span class="built_in">size</span>());</span><br><span class="line">    ofs.<span class="built_in">write</span>(<span class="built_in">reinterpret_cast</span>&lt;<span class="type">char</span> *&gt;(golden_input_inorder_int8.<span class="built_in">data</span>()), golden_input_inorder_int8.<span class="built_in">size</span>() * <span class="built_in">sizeof</span>(<span class="type">int8_t</span>));</span><br><span class="line">    ofs.<span class="built_in">close</span>();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// output</span></span><br><span class="line">    name = path_prefix + <span class="string">&quot;resize_output_bilinear.bin&quot;</span>;</span><br><span class="line">    ofs.<span class="built_in">open</span>(name, std::ios::binary | std::ios::out);</span><br><span class="line">    <span class="built_in">assert</span>((oh_ * ow_ * oc_ * total_tile_num_) == golden_output_int8.<span class="built_in">size</span>());</span><br><span class="line">    ofs.<span class="built_in">write</span>(<span class="built_in">reinterpret_cast</span>&lt;<span class="type">char</span> *&gt;(golden_output_int8.<span class="built_in">data</span>()), golden_output_int8.<span class="built_in">size</span>() * <span class="built_in">sizeof</span>(<span class="type">int8_t</span>));</span><br><span class="line">    ofs.<span class="built_in">close</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">ResizeCpuOp::float_to_int8</span><span class="params">(std::vector&lt;<span class="type">float</span>&gt;&amp; input_data, std::vector&lt;<span class="type">int8_t</span>&gt;&amp; output_data)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; input_data.<span class="built_in">size</span>(); ++i) &#123;</span><br><span class="line">        <span class="comment">// Round the data</span></span><br><span class="line">        <span class="type">float</span> rounded_data = std::<span class="built_in">round</span>(input_data[i]);</span><br><span class="line">        <span class="comment">// Truncate the data to the specified range</span></span><br><span class="line">        rounded_data = std::<span class="built_in">min</span>(std::<span class="built_in">max</span>(rounded_data, min_value), max_value);</span><br><span class="line">        <span class="comment">// Convert the data to int8_t type</span></span><br><span class="line">        output_data[i] = <span class="built_in">static_cast</span>&lt;<span class="type">int8_t</span>&gt;(rounded_data);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> BILINEAR_MODE</span></span><br><span class="line"><span class="comment">// =================================== bilinear mode ===================================</span></span><br><span class="line"><span class="function"><span class="type">resize_golden_t</span> <span class="title">ResizeCpuOp::GenGoldenOutput</span><span class="params">(<span class="type">const</span> <span class="type">resize_golden_t</span>&amp; input)</span> </span>&#123;</span><br><span class="line">    <span class="type">float</span> scale_factor_true_h = (oh_ &gt;= ih_) ? (<span class="type">float</span>)(ih_ - <span class="number">1</span>)/(oh_ - <span class="number">1</span>) : (<span class="type">float</span>)(oh_ - <span class="number">1</span>)/(ih_ - <span class="number">1</span>);   <span class="comment">// 确定align_true缩放倍数</span></span><br><span class="line">    <span class="type">float</span> scale_factor_true_w = (ow_ &gt;= iw_) ? (<span class="type">float</span>)(iw_ - <span class="number">1</span>)/(ow_ - <span class="number">1</span>) : (<span class="type">float</span>)(ow_ - <span class="number">1</span>)/(iw_ - <span class="number">1</span>);</span><br><span class="line">    <span class="type">float</span> scale_factor_false_h = (oh_ &gt;= ih_) ? (<span class="type">float</span>)ih_/oh_ : (<span class="type">float</span>)oh_/ih_;                          <span class="comment">// 确定align_false缩放倍数</span></span><br><span class="line">    <span class="type">float</span> scale_factor_false_w = (ow_ &gt;= iw_) ? (<span class="type">float</span>)iw_/ow_ : (<span class="type">float</span>)ow_/iw_;</span><br><span class="line">    <span class="type">float</span> src_h = <span class="number">0</span>;</span><br><span class="line">    <span class="type">float</span> src_w = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">std::vector&lt;<span class="type">float</span>&gt; <span class="title">golden_weight_pytorch</span><span class="params">(<span class="number">4</span> * oh_ * ow_)</span></span>;</span><br><span class="line">    <span class="function">std::vector&lt;<span class="type">float</span>&gt; <span class="title">golden_temp_outputs</span><span class="params">(oh_ * ow_ * oc_ * total_tile_num_)</span></span>;</span><br><span class="line">    <span class="function">std::vector&lt;<span class="type">float</span>&gt; <span class="title">outputs_temp_pytorch</span><span class="params">(oh_ * ow_ * oc_ * total_tile_num_)</span></span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> idx_n = <span class="number">0</span>; idx_n &lt; total_tile_num_; ++idx_n) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> idx_oh = <span class="number">0</span>; idx_oh &lt; oh_; ++idx_oh) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> idx_ow = <span class="number">0</span>; idx_ow &lt; ow_; ++idx_ow) &#123;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (if_align_corner_true) &#123;</span><br><span class="line">                    src_h = idx_oh * scale_factor_true_h ;      <span class="comment">// H方向</span></span><br><span class="line">                    src_w = idx_ow * scale_factor_true_w;       <span class="comment">// W方向</span></span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    src_h = (idx_oh + <span class="number">0.5</span>) * scale_factor_false_h - <span class="number">0.5</span>;     <span class="comment">// H方向</span></span><br><span class="line">                    src_w = (idx_ow + <span class="number">0.5</span>) * scale_factor_false_w - <span class="number">0.5</span>;     <span class="comment">// W方向</span></span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="type">float</span> h_weights_up = (<span class="built_in">ceil</span>(src_h) != src_h) ? <span class="built_in">ceil</span>(src_h) - src_h : <span class="number">1</span>;          <span class="comment">// 1 - u</span></span><br><span class="line">                <span class="type">float</span> h_weights_down = <span class="number">1</span> - h_weights_up;                                        <span class="comment">// u</span></span><br><span class="line">                <span class="type">float</span> w_weights_left = (<span class="built_in">ceil</span>(src_w) != src_w) ? <span class="built_in">ceil</span>(src_w) - src_w : <span class="number">1</span>;        <span class="comment">// 1 - v</span></span><br><span class="line">                <span class="type">float</span> w_weights_right = <span class="number">1</span> - w_weights_left;                                     <span class="comment">// v</span></span><br><span class="line"></span><br><span class="line">                <span class="type">int</span> h_indices_up = std::<span class="built_in">max</span>(<span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">floor</span>(src_h)), <span class="number">0</span>);</span><br><span class="line">                <span class="type">int</span> h_indices_down = std::<span class="built_in">min</span>(<span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">floor</span>(src_h) + <span class="number">1</span>), <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(ih_ - <span class="number">1</span>));</span><br><span class="line">                <span class="type">int</span> w_indices_left = std::<span class="built_in">max</span>(<span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">floor</span>(src_w)), <span class="number">0</span>);</span><br><span class="line">                <span class="type">int</span> w_indices_right = std::<span class="built_in">min</span>(<span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(<span class="built_in">floor</span>(src_w) + <span class="number">1</span>), <span class="built_in">static_cast</span>&lt;<span class="type">int</span>&gt;(iw_ - <span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">                <span class="comment">// weight index</span></span><br><span class="line">                <span class="type">int</span> idx_weight = idx_oh * ow_ + idx_ow;</span><br><span class="line">                <span class="type">int</span> idx_w00 = idx_weight;</span><br><span class="line">                <span class="type">int</span> idx_w01 = idx_w00 + oh_ * ow_;</span><br><span class="line">                <span class="type">int</span> idx_w10 = idx_w01 + oh_ * ow_;</span><br><span class="line">                <span class="type">int</span> idx_w11 = idx_w10 + oh_ * ow_;</span><br><span class="line"></span><br><span class="line">                golden_weight_pytorch[idx_w00] = h_weights_up * w_weights_left;</span><br><span class="line">                golden_weight_pytorch[idx_w01] = h_weights_up * w_weights_right;</span><br><span class="line">                golden_weight_pytorch[idx_w10] = h_weights_down * w_weights_left;</span><br><span class="line">                golden_weight_pytorch[idx_w11] = h_weights_down * w_weights_right;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// golden_output</span></span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> idx_c = <span class="number">0</span>; idx_c &lt; oc_; ++idx_c) &#123;</span><br><span class="line">                    <span class="comment">// input_buffer index</span></span><br><span class="line">                    <span class="type">int</span> idx_ib_00 = idx_n * oh_ * ow_ * ic_ * <span class="number">4</span> + idx_oh * ow_ * ic_ + idx_ow * ic_ + idx_c;</span><br><span class="line">                    <span class="type">int</span> idx_ib_01 = idx_ib_00 + oh_ * ow_ * ic_;</span><br><span class="line">                    <span class="type">int</span> idx_ib_10 = idx_ib_01 + oh_ * ow_ * ic_;</span><br><span class="line">                    <span class="type">int</span> idx_ib_11 = idx_ib_10 + oh_ * ow_ * ic_;</span><br><span class="line"></span><br><span class="line">                    <span class="comment">// input index</span></span><br><span class="line">                    <span class="type">int</span> idx_i00 = h_indices_up * iw_ * total_ic_ + w_indices_left * total_ic_ + idx_n * ic_ + idx_c;</span><br><span class="line">                    <span class="type">int</span> idx_i01 = h_indices_up * iw_ * total_ic_ + w_indices_right * total_ic_ + idx_n * ic_ + idx_c;</span><br><span class="line">                    <span class="type">int</span> idx_i10 = h_indices_down * iw_ * total_ic_ + w_indices_left * total_ic_ + idx_n * ic_ + idx_c;</span><br><span class="line">                    <span class="type">int</span> idx_i11 = h_indices_down * iw_ * total_ic_ + w_indices_right * total_ic_ + idx_n * ic_ + idx_c;</span><br><span class="line"></span><br><span class="line">                    <span class="type">int</span> idx_elem_inorder = idx_n * oh_ * ow_ * oc_ + idx_oh * ow_ * oc_ + idx_ow * oc_ + idx_c;</span><br><span class="line">                    <span class="type">int</span> idx_elem = idx_oh * ow_ * total_ic_ + idx_ow * total_ic_ + idx_n * oc_ + idx_c;</span><br><span class="line"></span><br><span class="line">                    golden_temp_outputs.<span class="built_in">at</span>(idx_elem_inorder) = golden_weight_pytorch[idx_w00] * input.<span class="built_in">at</span>(idx_i00) +</span><br><span class="line">                                                               golden_weight_pytorch[idx_w01] * input.<span class="built_in">at</span>(idx_i01) +</span><br><span class="line">                                                               golden_weight_pytorch[idx_w10] * input.<span class="built_in">at</span>(idx_i10) +</span><br><span class="line">                                                               golden_weight_pytorch[idx_w11] * input.<span class="built_in">at</span>(idx_i11);</span><br><span class="line"></span><br><span class="line">                    outputs_temp_pytorch.<span class="built_in">at</span>(idx_elem) = golden_temp_outputs.<span class="built_in">at</span>(idx_elem_inorder);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">float_to_int8</span>(golden_temp_outputs, golden_output_int8);</span><br><span class="line">    <span class="built_in">float_to_int8</span>(outputs_temp_pytorch, golden_output_inorder_int8);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> golden_output_int8;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line"><span class="comment">// =================================== nearest mode ===================================</span></span><br><span class="line"><span class="function"><span class="type">resize_golden_t</span> <span class="title">ResizeCpuOp::GenGoldenOutput</span><span class="params">(<span class="type">resize_golden_t</span> input)</span> </span>&#123;</span><br><span class="line">    <span class="type">float</span> ratio_h = (<span class="type">float</span>)ih_ / (<span class="type">float</span>)oh_;</span><br><span class="line">    <span class="type">float</span> ratio_w = (<span class="type">float</span>)iw_ / (<span class="type">float</span>)ow_;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> idx_n = <span class="number">0</span>; idx_n &lt; total_tile_num_; ++idx_n) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> idx_oh = <span class="number">0</span>; idx_oh &lt; oh_; ++idx_oh) &#123;</span><br><span class="line">            <span class="type">int</span> idx_ih = <span class="built_in">floor</span>(idx_oh * ratio_h);</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> idx_ow = <span class="number">0</span>; idx_ow &lt; ow_; ++idx_ow) &#123;</span><br><span class="line">                <span class="type">int</span> idx_iw = <span class="built_in">floor</span>(idx_ow * ratio_w);</span><br><span class="line"></span><br><span class="line">                <span class="type">int</span> idx_elem_inorder = idx_n * oh_ * ow_ * oc_ + idx_oh * ow_ * oc_ + idx_ow * oc_ + idx_c;</span><br><span class="line">                <span class="keyword">for</span> (<span class="type">int</span> idx_c = <span class="number">0</span>; idx_c &lt; oc_; ++idx_c) &#123;</span><br><span class="line">                    <span class="type">int</span> idx_src = idx_ih * iw_ * total_ic_ + idx_iw * total_ic_ + idx_n * ic_ + idx_c;</span><br><span class="line">                    golden_output_int8.<span class="built_in">at</span>(idx_elem_inorder) = input.<span class="built_in">at</span>(idx_src);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> golden_output_int8;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="Rotate"><a href="#Rotate" class="headerlink" title="Rotate"></a>Rotate</h1><h2 id="Research-1"><a href="#Research-1" class="headerlink" title="Research"></a>Research</h2><blockquote>
<ul>
<li>pytorch文档: <span class="exturl" data-url="aHR0cHM6Ly9weXRvcmNoLm9yZy92aXNpb24vc3RhYmxlL2dlbmVyYXRlZC90b3JjaHZpc2lvbi50cmFuc2Zvcm1zLmZ1bmN0aW9uYWwucm90YXRlLmh0bWw=">rotate</span></li>
</ul>
</blockquote>
<h3 id="resize-parameter-1"><a href="#resize-parameter-1" class="headerlink" title="resize parameter"></a>resize parameter</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.nn.functional.interpolate(<span class="built_in">input</span>, size=<span class="literal">None</span>, scale_factor=<span class="literal">None</span>, mode=<span class="string">&#x27;nearest&#x27;</span>, align_corners=<span class="literal">None</span>, recompute_scale_factor=<span class="literal">None</span>, antialias=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>rotate parameter:<ul>
<li>img (PIL Image or Tensor) – image to be rotated.</li>
<li>angle (number) – rotation angle value in degrees, counter-clockwise.</li>
<li>interpolation (InterpolationMode) – Desired interpolation enum defined by torchvision.transforms.InterpolationMode. Default is InterpolationMode.NEAREST. If input is Tensor, only InterpolationMode.NEAREST, InterpolationMode.BILINEAR are supported. The corresponding Pillow integer constants, e.g. PIL.Image.BILINEAR are accepted as well.</li>
<li>expand (bool, optional) – Optional expansion flag. If true, expands the output image to make it large enough to hold the entire rotated image. If false or omitted, make the output image the same size as the input image. Note that the expand flag assumes rotation around the center and no translation.</li>
<li>center (sequence, optional) – Optional center of rotation. Origin is the upper left corner. Default is the center of the image.</li>
<li>fill (sequence or number, optional) –</li>
<li>Pixel fill value for the area outside the transformed image. If given a number, the value is used for all bands respectively.</li>
</ul>
</li>
</ul>
<h2 id="Implement-1"><a href="#Implement-1" class="headerlink" title="Implement"></a>Implement</h2><h3 id="验证-1"><a href="#验证-1" class="headerlink" title="验证"></a>验证</h3><h4 id="Python-1"><a href="#Python-1" class="headerlink" title="Python"></a>Python</h4><h5 id="HW切分"><a href="#HW切分" class="headerlink" title="HW切分"></a>HW切分</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set constants</span></span><br><span class="line">N, H, W, C = <span class="number">1</span>, <span class="number">400</span>, <span class="number">200</span>, <span class="number">256</span>  <span class="comment"># Input tensor shape</span></span><br><span class="line">INTERPOLATION_MODE = torchvision.transforms.InterpolationMode.NEAREST  <span class="comment"># Interpolation mode</span></span><br><span class="line">CENTER = (W/<span class="number">2</span>, H/<span class="number">2</span>)  <span class="comment"># Rotation center</span></span><br><span class="line">ANGLE = -<span class="number">1.0353196091174368</span></span><br><span class="line"><span class="comment"># ANGLE = 180</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_args</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Parse command-line arguments&quot;&quot;&quot;</span></span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&quot;Rotate a tensor and save input and output.&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-c&#x27;</span>, <span class="string">&#x27;--idx_c&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">0</span>, <span class="built_in">help</span>=<span class="string">&#x27;Channel index to print and save.&#x27;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-m&#x27;</span>, <span class="string">&#x27;--data_mode&#x27;</span>, <span class="built_in">type</span>=<span class="built_in">int</span>, default=<span class="number">0</span>, choices=[<span class="number">0</span>, <span class="number">1</span>], <span class="built_in">help</span>=<span class="string">&#x27;Mode to generate data: 0 for random, 1 for sequential.&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_data</span>(<span class="params">data_mode</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Generate input data&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> data_mode ==<span class="string">&#x27;sequential&#x27;</span>:</span><br><span class="line">        <span class="comment"># Generate data with sequential values in WH direction</span></span><br><span class="line">        <span class="keyword">return</span> np.tile(np.arange(H * W, dtype=np.int8).reshape(H, W, <span class="number">1</span>), (N, <span class="number">1</span>, <span class="number">1</span>, C))</span><br><span class="line">    <span class="keyword">elif</span> data_mode == <span class="string">&#x27;random&#x27;</span>:</span><br><span class="line">        <span class="comment"># Generate random data</span></span><br><span class="line">        <span class="keyword">return</span> np.random.randint(-<span class="number">128</span>, <span class="number">128</span>, size=(N, H, W, C), dtype=np.int8)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rotate_tensor</span>(<span class="params">tensor, angle</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Rotate a tensor using PyTorch&#x27;s rotate function&quot;&quot;&quot;</span></span><br><span class="line">    tensor_nchw = tensor.permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    rotated_tensor_nchw = F.rotate(tensor_nchw, angle=angle, interpolation=INTERPOLATION_MODE, center=CENTER)</span><br><span class="line">    <span class="keyword">return</span> rotated_tensor_nchw.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_data</span>(<span class="params">data, filename</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Save data to a binary file&quot;&quot;&quot;</span></span><br><span class="line">    data.tofile(filename)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Data saved to: <span class="subst">&#123;filename&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    args = parse_args()</span><br><span class="line">    idx_c = args.idx_c</span><br><span class="line">    data_mode = <span class="string">&#x27;random&#x27;</span> <span class="keyword">if</span> args.data_mode == <span class="number">0</span> <span class="keyword">else</span><span class="string">&#x27;sequential&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Generate input data</span></span><br><span class="line">    input_nhwc_np = generate_data(data_mode)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save input data</span></span><br><span class="line">    save_data(input_nhwc_np, <span class="string">&#x27;input_rotate_nhwc.bin&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Input numpy array (NHWC) channel <span class="subst">&#123;idx_c&#125;</span>:\n&quot;</span>, input_nhwc_np[<span class="number">0</span>, :, :, idx_c])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Convert to torch tensor</span></span><br><span class="line">    input_nhwc_tensor = torch.from_numpy(input_nhwc_np)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Rotate tensor</span></span><br><span class="line">    rotated_tensor_nhwc = rotate_tensor(input_nhwc_tensor, angle=ANGLE)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Save output data</span></span><br><span class="line">    output_nhwc_np = rotated_tensor_nhwc.numpy()</span><br><span class="line">    save_data(output_nhwc_np, <span class="string">&#x27;output_rotate_nhwc.bin&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Output numpy array (NHWC) channel <span class="subst">&#123;idx_c&#125;</span>:\n&quot;</span>, output_nhwc_np[<span class="number">0</span>, :, :, idx_c])</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="IC切分"><a href="#IC切分" class="headerlink" title="IC切分"></a>IC切分</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics.pairwise <span class="keyword">import</span> cosine_similarity</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_squared_error</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置打印选项</span></span><br><span class="line">np.set_printoptions(linewidth=<span class="number">400</span>)</span><br><span class="line">torch.set_printoptions(linewidth=<span class="number">200</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置参数</span></span><br><span class="line">ENABLE_FP8_DATA_TYPE = <span class="literal">True</span></span><br><span class="line">ENABLE_OUTPUT_BINARY = <span class="literal">True</span></span><br><span class="line">ENABLE_PRINT = <span class="literal">True</span></span><br><span class="line">ENABLE_NHWC_2_NCHW = <span class="literal">True</span></span><br><span class="line">INTERPOLATE_MODE = <span class="string">&quot;nearest&quot;</span></span><br><span class="line">N, C, H, W = <span class="number">32</span>, <span class="number">8</span>, <span class="number">400</span>, <span class="number">200</span>  <span class="comment"># tile_num, Channels, Height, Width</span></span><br><span class="line">center = (W/<span class="number">2</span>, H/<span class="number">2</span>)</span><br><span class="line">DATA_PATH = <span class="string">&quot;/home/dugen/scc_dxm/project_dxm/golden_data/rotate&quot;</span></span><br><span class="line">dtype = np.uint8 <span class="keyword">if</span> ENABLE_FP8_DATA_TYPE <span class="keyword">else</span> np.int8</span><br><span class="line">interpolation_mode = torchvision.transforms.InterpolationMode.NEAREST</span><br><span class="line"></span><br><span class="line"><span class="comment"># 居中打印</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">print_centered</span>(<span class="params">text</span>):</span><br><span class="line">    terminal_size = os.get_terminal_size().columns</span><br><span class="line">    <span class="built_in">print</span>(text.center(terminal_size))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">parse_args</span>():</span><br><span class="line">    parser = argparse.ArgumentParser(description=<span class="string">&quot;Process one or more frames.&quot;</span>)</span><br><span class="line">    parser.add_argument(<span class="string">&#x27;-f&#x27;</span>, <span class="string">&#x27;--frame&#x27;</span>, nargs=<span class="string">&#x27;+&#x27;</span>, dest=<span class="string">&#x27;frame_ids&#x27;</span>, required=<span class="literal">True</span>, <span class="built_in">help</span>=<span class="string">&#x27;Frame ID(s) to process.&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> parser.parse_args()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取二进制文件</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_bin_file</span>(<span class="params">file_path, dtype</span>):</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(file_path):</span><br><span class="line">        <span class="keyword">return</span> np.fromfile(file_path, dtype=dtype)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print_centered(<span class="string">&quot;File does not exist:&quot;</span>, file_path)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取角度值</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">read_angle_from_bin_file</span>(<span class="params">file_path</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(file_path):</span><br><span class="line">        print_centered(<span class="string">&quot;Angle file does not exist:&quot;</span>, file_path)</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span>, <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_path, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> file:</span><br><span class="line">        angle_fp64 = np.fromfile(file_path, dtype=np.float32)[<span class="number">0</span>]</span><br><span class="line">        angle_fp32 = <span class="built_in">float</span>(angle_fp64)</span><br><span class="line">    <span class="keyword">return</span> angle_fp32, angle_fp64</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">transform_and_save</span>(<span class="params">data, original_layout, N, H, W, C, filename_prefix</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    此函数将保存的文件路径修改为脚本所在目录的data_pytorch子目录。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    save_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), <span class="string">&#x27;data_pytorch&#x27;</span>)</span><br><span class="line">    os.makedirs(save_dir, exist_ok=<span class="literal">True</span>)  <span class="comment"># 确保目录存在</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> original_layout == <span class="string">&#x27;NCHW&#x27;</span>:</span><br><span class="line">        tensor = torch.from_numpy(data.reshape(N, C, H, W))</span><br><span class="line">    <span class="keyword">elif</span> original_layout == <span class="string">&#x27;NHWC&#x27;</span>:</span><br><span class="line">        tensor = torch.from_numpy(data.reshape(N, H, W, C)).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">&quot;Unsupported original layout. Expected &#x27;NCHW&#x27; or &#x27;NHWC&#x27;.&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 文件保存路径调整</span></span><br><span class="line">    filename_nchw = os.path.join(save_dir, <span class="string">f&quot;rotate_<span class="subst">&#123;INTERPOLATE_MODE&#125;</span>_pytorch_<span class="subst">&#123;filename_prefix&#125;</span>_nchw.bin&quot;</span>)</span><br><span class="line">    tensor.numpy().tofile(filename_nchw)</span><br><span class="line">    print_centered(<span class="string">f&quot;Saved NCHW layout to <span class="subst">&#123;filename_nchw&#125;</span>, shape: <span class="subst">&#123;tensor.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    tensor_nhwc = tensor.permute(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    filename_nhwc = os.path.join(save_dir, <span class="string">f&quot;rotate_<span class="subst">&#123;INTERPOLATE_MODE&#125;</span>_pytorch_<span class="subst">&#123;filename_prefix&#125;</span>_nhwc.bin&quot;</span>)</span><br><span class="line">    tensor_nhwc.numpy().tofile(filename_nhwc)</span><br><span class="line">    print_centered(<span class="string">f&quot;Saved NHWC layout to <span class="subst">&#123;filename_nhwc&#125;</span>, shape: <span class="subst">&#123;tensor_nhwc.shape&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tensor余弦相似度与MSE比较</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">tensor_cosine_similarity</span>(<span class="params">tensor_a, tensor_b, thd=<span class="number">0.999</span></span>):</span><br><span class="line">    tensor_a = tensor_a.numpy().reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line">    tensor_b = tensor_b.numpy().reshape(<span class="number">1</span>, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        cos_sim = cosine_similarity(tensor_a, tensor_b)[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line">        mse = mean_squared_error(tensor_a, tensor_b)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        print_centered(<span class="string">f&quot;Error calculating metrics: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        sys.exit(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    result = <span class="string">&#x27;pass&#x27;</span> <span class="keyword">if</span> cos_sim &gt; thd <span class="keyword">else</span> <span class="string">&#x27;fail&#x27;</span></span><br><span class="line">    print_centered(<span class="string">f&quot;Cosine similarity: <span class="subst">&#123;cos_sim&#125;</span>, Mean square error: <span class="subst">&#123;mse&#125;</span>, Test result: <span class="subst">&#123;result&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span> <span class="keyword">if</span> result == <span class="string">&#x27;pass&#x27;</span> <span class="keyword">else</span> <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rotate_manual</span>(<span class="params">images_nchw, angle, interpolation_mode, center</span>):</span><br><span class="line">    N, C, H, W = images_nchw.shape</span><br><span class="line">    x_c, y_c = center[<span class="number">0</span>] - <span class="number">0.5</span>, center[<span class="number">1</span>] - <span class="number">0.5</span></span><br><span class="line">    angle_rad = math.radians(angle)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算 cos 和 sin 的值</span></span><br><span class="line">    cos_theta = math.cos(angle_rad)</span><br><span class="line">    sin_theta = math.sin(angle_rad)</span><br><span class="line">    x_center = x_c - x_c * cos_theta + y_c * sin_theta</span><br><span class="line">    y_center = y_c - x_c * sin_theta - y_c * cos_theta</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建一个与输入相同形状的张量来存储旋转后的图像</span></span><br><span class="line">    rotated_images_nchw_optimized = torch.zeros_like(images_nchw)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 创建网格</span></span><br><span class="line">    y_grid, x_grid = torch.meshgrid(torch.arange(H), torch.arange(W), indexing=<span class="string">&#x27;ij&#x27;</span>)  </span><br><span class="line">    y_grid = y_grid.<span class="built_in">float</span>()</span><br><span class="line">    x_grid = x_grid.<span class="built_in">float</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算旋转后的位置</span></span><br><span class="line">    y_i = x_grid * sin_theta + y_grid * cos_theta + y_center</span><br><span class="line">    x_i = x_grid * cos_theta - y_grid * sin_theta + x_center</span><br><span class="line">    a1 = y_i</span><br><span class="line">    b1 = x_i</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将新位置的值赋给输出张量的对应位置</span></span><br><span class="line">    x_ir = torch.<span class="built_in">round</span>(x_i).long()</span><br><span class="line">    y_ir = torch.<span class="built_in">round</span>(y_i).long()</span><br><span class="line"></span><br><span class="line">    x_i = torch.clamp(x_ir, <span class="number">0</span>, W-<span class="number">1</span>)</span><br><span class="line">    y_i = torch.clamp(y_ir, <span class="number">0</span>, H-<span class="number">1</span>)</span><br><span class="line">    mask = (x_ir &gt;= <span class="number">0</span>) &amp; (x_ir &lt; W) &amp; (y_ir &gt;= <span class="number">0</span>) &amp; (y_ir &lt; H)</span><br><span class="line"></span><br><span class="line">    rotated_images_nchw_optimized[:, :, mask] = images_nchw[:, :, y_i[mask], x_i[mask]]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> ENABLE_PRINT:</span><br><span class="line">        <span class="comment"># 在 c, h, w 维度进行打印</span></span><br><span class="line">        <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(C):</span><br><span class="line">            <span class="keyword">for</span> h <span class="keyword">in</span> <span class="built_in">range</span>(H):</span><br><span class="line">                <span class="keyword">for</span> w <span class="keyword">in</span> <span class="built_in">range</span>(W):</span><br><span class="line">                    <span class="keyword">if</span> mask[h, w]:</span><br><span class="line">                        print_centered(<span class="string">f&quot;(c, y, x) = (<span class="subst">&#123;c&#125;</span>, <span class="subst">&#123;h&#125;</span>, <span class="subst">&#123;w&#125;</span>)\t(y_i, x_i) = (<span class="subst">&#123;a1[h, w]&#125;</span>, <span class="subst">&#123;b1[h, w]&#125;</span>)\t(round_yi, round_xi) = (<span class="subst">&#123;y_ir[h, w]&#125;</span>, <span class="subst">&#123;x_ir[h, w]&#125;</span>)\t(int_yi, int_xi) = (<span class="subst">&#123;y_i[h, w]&#125;</span>, <span class="subst">&#123;x_i[h, w]&#125;</span>)&quot;</span>)</span><br><span class="line">                        <span class="comment"># print_centered(f&quot;rotated_images_nchw_optimized[&#123;c&#125;, &#123;h&#125;, &#123;w&#125;] = &#123;rotated_images_nchw_optimized[c, h, w]&#125;&quot;)</span></span><br><span class="line">                        <span class="comment"># print_centered(f&quot;images_nchw[&#123;c&#125;, &#123;y_i[h, w]&#125;, &#123;x_i[h, w]&#125;] = &#123;images_nchw[c, y_i[h, w], x_i[h, w]]&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        print_centered(<span class="string">f&quot;==================== default close rotate debug print func ====================\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> rotated_images_nchw_optimized</span><br><span class="line"><span class="comment">##################################### PYTHON_MANUAL_ROTATE_FUNC #####################################</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 主函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    args = parse_args()</span><br><span class="line">    frame_ids = args.frame_ids  <span class="comment"># 这将是一个帧ID列表</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> frame_id <span class="keyword">in</span> frame_ids:</span><br><span class="line">        frame = <span class="string">f&quot;frame<span class="subst">&#123;frame_id&#125;</span>&quot;</span></span><br><span class="line">        print_centered(<span class="string">f&quot;Testing <span class="subst">&#123;frame&#125;</span>...&quot;</span>)</span><br><span class="line"></span><br><span class="line">        input_name = <span class="string">f&quot;<span class="subst">&#123;DATA_PATH&#125;</span>/<span class="subst">&#123;frame&#125;</span>/Input.prev_bev.32x400x200x8.fp8.bin&quot;</span></span><br><span class="line">        angle_name = <span class="string">f&quot;<span class="subst">&#123;DATA_PATH&#125;</span>/<span class="subst">&#123;frame&#125;</span>/Input.angle.fp32.bin&quot;</span></span><br><span class="line">        output_name = <span class="string">f&quot;<span class="subst">&#123;DATA_PATH&#125;</span>/<span class="subst">&#123;frame&#125;</span>/Golden.prev_bev_out.32x400x200x8.fp8.bin&quot;</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 读取输入和输出数据</span></span><br><span class="line">        input_bin = read_bin_file(input_name, dtype)</span><br><span class="line">        output_bin = read_bin_file(output_name, dtype)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> ENABLE_NHWC_2_NCHW:</span><br><span class="line">            original_layout = <span class="string">&#x27;NHWC&#x27;</span></span><br><span class="line">            input_tensor = torch.from_numpy(input_bin.reshape(N, H, W, C)).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">            output_tensor = torch.from_numpy(output_bin.reshape(N, H, W, C)).permute(<span class="number">0</span>, <span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            original_layout = <span class="string">&#x27;NCHW&#x27;</span></span><br><span class="line">            input_tensor = torch.from_numpy(input_bin.reshape(N, C, H, W))</span><br><span class="line">            output_tensor = torch.from_numpy(output_bin.reshape(N, C, H, W))</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> ENABLE_OUTPUT_BINARY:</span><br><span class="line">            output_tensor = rotate_manual(input_tensor, angle_fp32, interpolation_mode, center)</span><br><span class="line"></span><br><span class="line">        transform_and_save(input_bin, original_layout, N, H, W, C, <span class="string">f&#x27;<span class="subst">&#123;frame&#125;</span>_input&#x27;</span>)</span><br><span class="line">        transform_and_save(output_bin, original_layout, N, H, W, C, <span class="string">f&#x27;<span class="subst">&#123;frame&#125;</span>_output&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 读取角度</span></span><br><span class="line">        angle_fp32, angle_fp64 = read_angle_from_bin_file(angle_name) <span class="keyword">if</span> os.path.exists(angle_name) <span class="keyword">else</span> (<span class="number">0.0</span>, <span class="number">0.0</span>)</span><br><span class="line">        print_centered(<span class="string">f&quot;[<span class="subst">&#123;frame&#125;</span>] angle (fp64): <span class="subst">&#123;angle_fp64:<span class="number">.9</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        print_centered(<span class="string">f&quot;[<span class="subst">&#123;frame&#125;</span>] angle (fp32): <span class="subst">&#123;angle_fp32:<span class="number">.9</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        rotated_pytorch_tensor = torchvision.transforms.functional.rotate(</span><br><span class="line">            input_tensor, angle=angle_fp32, interpolation=interpolation_mode, center=center)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 比较结果</span></span><br><span class="line">        comparison_result = tensor_cosine_similarity(rotated_pytorch_tensor, output_tensor)</span><br><span class="line">        print_centered(<span class="string">f&quot;[<span class="subst">&#123;frame&#125;</span>] Comparison result: <span class="subst">&#123;<span class="string">&#x27;Pass&#x27;</span> <span class="keyword">if</span> comparison_result <span class="keyword">else</span> <span class="string">&#x27;Fail&#x27;</span>&#125;</span>\n&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>


<h1 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h1>
      <div class="tags">
          <a href="/tags/Rotate/" rel="tag"><i class="ic i-tag"></i> Rotate</a>
          <a href="/tags/Resize/" rel="tag"><i class="ic i-tag"></i> Resize</a>
      </div>
  </div>

   <footer>

    <div class="meta">
  <span class="item">
    <span class="icon">
      <i class="ic i-calendar-check"></i>
    </span>
    <span class="text">Edited on</span>
    <time title="Modified: 2024-05-04 19:43:01" itemprop="dateModified" datetime="2024-05-04T19:43:01+08:00">2024-05-04</time>
  </span>
</div>

      
<div class="reward">
  <button><i class="ic i-heartbeat"></i> Donate</button>
  <p>Give me a cup of [coffee]~(￣▽￣)~*</p>
  <div id="qr">
      
      <div>
        <img data-src="/images/wechatpay.png" alt="dxm WeChat Pay">
        <p>WeChat Pay</p>
      </div>
      
      <div>
        <img data-src="/images/alipay.png" alt="dxm Alipay">
        <p>Alipay</p>
      </div>
  </div>
</div>

      

<div id="copyright">
<ul>
  <li class="author">
    <strong>Post author:  </strong>dxm <i class="ic i-at"><em>@</em></i>blog_dxm
  </li>
  <li class="link">
    <strong>Post link: </strong>
    <a href="http://example.com/2024/04/25/job/operator/rotate/" title="Rotate">http://example.com/2024/04/25/job/operator/rotate/</a>
  </li>
  <li class="license">
    <strong>Copyright Notice:  </strong>All articles in this blog are licensed under <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> unless stating additionally.
  </li>
</ul>
</div>

  </footer>

</article>

  </div>
  

<div class="post-nav">
    <div class="item left">
      

  <a href="/2024/04/25/job/operator/convTranspose2d/" itemprop="url" rel="prev" data-background-image="&#x2F;2024&#x2F;04&#x2F;25&#x2F;job&#x2F;operator&#x2F;convTranspose2d&#x2F;wp_0005.jpg" title="ConvTranspose2d">
  <span class="type">Previous Post</span>
  <span class="category"><i class="ic i-flag"></i> 算子开发</span>
  <h3>ConvTranspose2d</h3>
  </a>

    </div>
    <div class="item right">
      

  <a href="/2024/04/25/note/tutorial_linux/" itemprop="url" rel="next" data-background-image="&#x2F;2024&#x2F;04&#x2F;25&#x2F;note&#x2F;tutorial_linux&#x2F;wp_0002.png" title="Tutorial-Linux">
  <span class="type">Next Post</span>
  <span class="category"><i class="ic i-flag"></i> Linux</span>
  <h3>Tutorial-Linux</h3>
  </a>

    </div>
</div>

  
  <div class="wrap" id="comments"></div>


        </div>
        <div id="sidebar">
          

<div class="inner">

  <div class="panels">
    <div class="inner">
      <div class="contents panel pjax" data-title="Contents">
          <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Resize"><span class="toc-number">1.</span> <span class="toc-text">Resize</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Research"><span class="toc-number">1.1.</span> <span class="toc-text">Research</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#resize-parameter"><span class="toc-number">1.1.1.</span> <span class="toc-text">resize parameter</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pytorch%E6%BA%90%E7%A0%81"><span class="toc-number">1.1.2.</span> <span class="toc-text">pytorch源码</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#bilinear-mode"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">bilinear mode</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#nearest-mode"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">nearest mode</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Implement"><span class="toc-number">1.2.</span> <span class="toc-text">Implement</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#resize%E8%A1%8C%E4%B8%BA"><span class="toc-number">1.2.1.</span> <span class="toc-text">resize行为</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%AC%E5%BC%8F%E6%8E%A8%E5%AF%BC"><span class="toc-number">1.2.1.1.</span> <span class="toc-text">公式推导</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#resize%E5%9B%BE%E7%A4%BA"><span class="toc-number">1.2.1.2.</span> <span class="toc-text">resize图示</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AA%8C%E8%AF%81"><span class="toc-number">1.2.2.</span> <span class="toc-text">验证</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Python"><span class="toc-number">1.2.2.1.</span> <span class="toc-text">Python</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#align-corner-true-bilinear"><span class="toc-number">1.2.2.1.1.</span> <span class="toc-text">align_corner &#x3D; true (bilinear)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#align-corner-false-bilinear"><span class="toc-number">1.2.2.1.2.</span> <span class="toc-text">align_corner &#x3D; false (bilinear)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#nearest-mode-1"><span class="toc-number">1.2.2.1.3.</span> <span class="toc-text">nearest mode</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#C"><span class="toc-number">1.2.2.2.</span> <span class="toc-text">C++</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#resize-hpp"><span class="toc-number">1.2.2.2.1.</span> <span class="toc-text">resize.hpp</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#resize-cpp"><span class="toc-number">1.2.2.2.2.</span> <span class="toc-text">resize.cpp</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Rotate"><span class="toc-number">2.</span> <span class="toc-text">Rotate</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Research-1"><span class="toc-number">2.1.</span> <span class="toc-text">Research</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#resize-parameter-1"><span class="toc-number">2.1.1.</span> <span class="toc-text">resize parameter</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Implement-1"><span class="toc-number">2.2.</span> <span class="toc-text">Implement</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AA%8C%E8%AF%81-1"><span class="toc-number">2.2.1.</span> <span class="toc-text">验证</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Python-1"><span class="toc-number">2.2.1.1.</span> <span class="toc-text">Python</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#HW%E5%88%87%E5%88%86"><span class="toc-number">2.2.1.1.1.</span> <span class="toc-text">HW切分</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#IC%E5%88%87%E5%88%86"><span class="toc-number">2.2.1.1.2.</span> <span class="toc-text">IC切分</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Others"><span class="toc-number">3.</span> <span class="toc-text">Others</span></a></li></ol>
      </div>
      <div class="related panel pjax" data-title="Related">
        <ul>
          <li><a href="/2024/04/25/job/operator/convTranspose2d/" rel="bookmark" title="ConvTranspose2d">ConvTranspose2d</a></li><li class="active"><a href="/2024/04/25/job/operator/rotate/" rel="bookmark" title="Rotate">Rotate</a></li>
        </ul>
      </div>
      <div class="overview panel" data-title="Overview">
        <div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <img class="image" itemprop="image" alt="dxm"
      data-src="/images/dxm.jpg">
  <p class="name" itemprop="name">dxm</p>
  <div class="description" itemprop="description"></div>
</div>

<nav class="state">
    <div class="item posts">
      <a href="/archives/">
        <span class="count">11</span>
        <span class="name">posts</span>
      </a>
    </div>
    <div class="item categories">
      <a href="/categories/">
        <span class="count">10</span>
        <span class="name">categories</span>
      </a>
    </div>
    <div class="item tags">
      <a href="/tags/">
        <span class="count">15</span>
        <span class="name">tags</span>
      </a>
    </div>
</nav>

<div class="social">
      <span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tLw==" title="https:&#x2F;&#x2F;github.com&#x2F;"><i class="ic i-github"></i></span>
      <span class="exturl item email" data-url="aHR0cHM6Ly9tYWlsLnFxLmNvbS9jZ2ktYmluL2ZyYW1lX2h0bWw/c2lkPWZremlPMlBjUWxSd01WUXkmcj04ODZkNjY5YmE3Yjg1MjAyNTk5NWIyZjQ1YmEzY2VmYSZsYW5nPXpo" title="https:&#x2F;&#x2F;mail.qq.com&#x2F;cgi-bin&#x2F;frame_html?sid&#x3D;fkziO2PcQlRwMVQy&amp;r&#x3D;886d669ba7b852025995b2f45ba3cefa&amp;lang&#x3D;zh"><i class="ic i-envelope"></i></span>
      <span class="exturl item zhihu" data-url="aHR0cHM6Ly93d3cuemhpaHUuY29tL2hvdA==" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;hot"><i class="ic i-zhihu"></i></span>
      <span class="exturl item music" data-url="aHR0cHM6Ly9tdXNpYy4xNjMuY29tLyMvbXkvbS9tdXNpYy9wbGF5bGlzdD9pZD00MDgyMTkzNTQ=" title="https:&#x2F;&#x2F;music.163.com&#x2F;#&#x2F;my&#x2F;m&#x2F;music&#x2F;playlist?id&#x3D;408219354"><i class="ic i-cloud-music"></i></span>
      <span class="exturl item bilibili" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tLw==" title="https:&#x2F;&#x2F;www.bilibili.com&#x2F;"><i class="ic i-bilibili"></i></span>
      <span class="exturl item youtube" data-url="aHR0cHM6Ly93d3cueW91dHViZS5jb20v" title="https:&#x2F;&#x2F;www.youtube.com&#x2F;"><i class="ic i-youtube"></i></span>
</div>

<ul class="menu">
  
    
  <li class="item">
    <a href="/" rel="section"><i class="ic i-home"></i>Home</a>
  </li>

    
  <li class="item">
    <a href="/about/" rel="section"><i class="ic i-user"></i>About</a>
  </li>

    
  <li class="item">
    <a href="/resume/" rel="section"><i class="ic i-user"></i>resume</a>
  </li>

        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-feather"></i>Posts</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/archives/" rel="section"><i class="ic i-list-alt"></i>Archives</a>
  </li>

        
  <li class="item">
    <a href="/categories/" rel="section"><i class="ic i-th"></i>Categories</a>
  </li>

        
  <li class="item">
    <a href="/tags/" rel="section"><i class="ic i-tags"></i>Tags</a>
  </li>

  </ul>
    
  <li class="item">
    <a href="/gallery/" rel="section"><i class="ic i-heart"></i>gallery</a>
  </li>

        
  <li class="item dropdown">
      <a href="javascript:void(0);"><i class="ic i-link-alt"></i>links</a>
    <ul class="submenu">

        
  <li class="item">
    <a href="/postgraduate/" rel="section"><i class="ic i-pen"></i>postgraduate</a>
  </li>

        
  <li class="item">
    <a href="/%E5%85%B4%E8%B6%A3/" rel="section"><i class="ic i-flag"></i>兴趣</a>
  </li>

        
  <li class="item">
    <a href="/%E5%9C%A8%E7%BA%BF%E5%B7%A5%E5%85%B7/" rel="section"><i class="ic i-edge"></i>在线工具</a>
  </li>

        
  <li class="item">
    <a href="/%E5%B7%A5%E4%BD%9C/" rel="section"><i class="ic i-coffee"></i>工作</a>
  </li>

        
  <li class="item">
    <a href="/%E8%AE%B0%E5%BF%86%E9%95%BF%E5%BB%8A/" rel="section"><i class="ic i-sakura"></i>记忆长廊</a>
  </li>

  </ul>

</ul>

      </div>
    </div>
  </div>

  <ul id="quick">
    <li class="prev pjax">
        <a href="/2024/04/25/job/operator/convTranspose2d/" rel="prev" title="Previous Post"><i class="ic i-chevron-left"></i></a>
    </li>
    <li class="up"><i class="ic i-arrow-up"></i></li>
    <li class="down"><i class="ic i-arrow-down"></i></li>
    <li class="next pjax">
        <a href="/2024/04/25/note/tutorial_linux/" rel="next" title="Next Post"><i class="ic i-chevron-right"></i></a>
    </li>
    <li class="percent"></li>
  </ul>
</div>


        </div>
        <div class="dimmer"></div>
      </div>
    </main>
    <footer id="footer">
      <div class="inner">
        <div class="widgets">
          
<div class="rpost pjax">
  <h2>Random Posts</h2>
  <ul>
      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/job/" title="In Job">Job</a>
<i class="ic i-angle-right"></i>
<a href="/categories/job/Compile/" title="In Compile">Compile</a>
</div>

    <span><a href="/2024/05/06/job/compile/mlir/" title="MLIR学习">MLIR学习</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Blog/" title="In Blog">Blog</a>
<i class="ic i-angle-right"></i>
<a href="/categories/Blog/Hexo/" title="In Hexo">Hexo</a>
<i class="ic i-angle-right"></i>
<a href="/categories/Blog/Hexo/Theme-Shoka-Documentation/" title="In Theme Shoka Documentation">Theme Shoka Documentation</a>
</div>

    <span><a href="/2020/08/13/note/theme-shoka-doc/special/" title="Step.4 主题特殊功能">Step.4 主题特殊功能</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/note/" title="In Note">Note</a>
</div>

    <span><a href="/2024/04/16/note/recording/" title="Recording-Blog">Recording-Blog</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Blog/" title="In Blog">Blog</a>
<i class="ic i-angle-right"></i>
<a href="/categories/Blog/Hexo/" title="In Hexo">Hexo</a>
<i class="ic i-angle-right"></i>
<a href="/categories/Blog/Hexo/Theme-Shoka-Documentation/" title="In Theme Shoka Documentation">Theme Shoka Documentation</a>
</div>

    <span><a href="/2020/08/13/note/theme-shoka-doc/config/" title="Step.2 基本配置">Step.2 基本配置</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/note/" title="In Note">Note</a>
<i class="ic i-angle-right"></i>
<a href="/categories/note/Linux/" title="In Linux">Linux</a>
</div>

    <span><a href="/2024/04/25/note/tutorial_linux/" title="Tutorial-Linux">Tutorial-Linux</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/gallery/" title="In Gallery">Gallery</a>
<i class="ic i-angle-right"></i>
<a href="/categories/gallery/Wallpaper/" title="In Wallpaper">Wallpaper</a>
</div>

    <span><a href="/2024/04/18/gallery/wallpaper/" title="Wallpaper">Wallpaper</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/job/" title="In Job">Job</a>
<i class="ic i-angle-right"></i>
<a href="/categories/job/%E7%AE%97%E5%AD%90%E5%BC%80%E5%8F%91/" title="In 算子开发">算子开发</a>
</div>

    <span><a href="/2024/04/25/job/operator/rotate/" title="Rotate">Rotate</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Blog/" title="In Blog">Blog</a>
<i class="ic i-angle-right"></i>
<a href="/categories/Blog/Hexo/" title="In Hexo">Hexo</a>
<i class="ic i-angle-right"></i>
<a href="/categories/Blog/Hexo/Theme-Shoka-Documentation/" title="In Theme Shoka Documentation">Theme Shoka Documentation</a>
</div>

    <span><a href="/2020/08/13/note/theme-shoka-doc/dependents/" title="Step.1 依赖插件">Step.1 依赖插件</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Blog/" title="In Blog">Blog</a>
<i class="ic i-angle-right"></i>
<a href="/categories/Blog/Hexo/" title="In Hexo">Hexo</a>
<i class="ic i-angle-right"></i>
<a href="/categories/Blog/Hexo/Theme-Shoka-Documentation/" title="In Theme Shoka Documentation">Theme Shoka Documentation</a>
</div>

    <span><a href="/2020/08/13/note/theme-shoka-doc/display/" title="Step.3 界面显示">Step.3 界面显示</a></span>
  </li>

      
  <li class="item">
    
<div class="breadcrumb">
<a href="/categories/Blog/" title="In Blog">Blog</a>
<i class="ic i-angle-right"></i>
<a href="/categories/Blog/Hexo/" title="In Hexo">Hexo</a>
<i class="ic i-angle-right"></i>
<a href="/categories/Blog/Hexo/Theme-Shoka-Documentation/" title="In Theme Shoka Documentation">Theme Shoka Documentation</a>
</div>

    <span><a href="/2020/08/13/note/theme-shoka-doc/theme-shoka-doc/" title="Hexo主题Shoka &amp; multi-markdown-it渲染器使用说明">Hexo主题Shoka & multi-markdown-it渲染器使用说明</a></span>
  </li>

  </ul>
</div>
<div>
  <h2>Recent Comments</h2>
  <ul class="leancloud-recent-comment"></ul>
</div>

        </div>
        <div class="status">
  <div class="copyright">
    
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="ic i-sakura rotate"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">dxm @ DDD</span>
  </div>
  <div class="count">
    <span class="post-meta-item-icon">
      <i class="ic i-chart-area"></i>
    </span>
    <span title="Symbols count total">110k words</span>

    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="ic i-coffee"></i>
    </span>
    <span title="Reading time total">1:40</span>
  </div>
  <div class="powered-by">
    Powered by <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span>
  </div>
</div>

      </div>
    </footer>
  </div>
<script data-config type="text/javascript">
  var LOCAL = {
    path: '2024/04/25/job/operator/rotate/',
    favicon: {
      show: "（●´3｀●）Goooood",
      hide: "(´Д｀)Booooom"
    },
    search : {
      placeholder: "Search for Posts",
      empty: "We didn't find any results for the search: ${query}",
      stats: "${hits} results found in ${time} ms"
    },
    valine: true,fancybox: true,
    copyright: 'Copied to clipboard successfully! <br> All articles in this blog are licensed under <i class="ic i-creative-commons"></i>BY-NC-SA.',
    ignores : [
      function(uri) {
        return uri.includes('#');
      },
      function(uri) {
        return new RegExp(LOCAL.path+"$").test(uri);
      }
    ]
  };
</script>

<script src="https://cdn.polyfill.io/v2/polyfill.js"></script>

<script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script>

<script src="/js/app.js?v=0.2.5"></script>




</body>
</html>
